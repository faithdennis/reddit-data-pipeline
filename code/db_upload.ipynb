{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd9c9ee8-8844-45a5-84fa-c4f20877d68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026f80d3-d54b-4a1f-8b69-c3530cf76b31",
   "metadata": {},
   "source": [
    "#### Check if data files have been extracted\n",
    "\n",
    "In theory, this notebook should be run after `EDA.ipynb` where we perform our intial data exploratory.\n",
    "In that notebook, we unzip the compressed data file into two `.ndjson` for submission and comment data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91b5f3d7-a6da-437a-ab5d-44ebea19195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_data_path = os.path.join(\"..\", \"data\", \"extracted_data\", \"comments_data.ndjson\")\n",
    "submissions_data_path = os.path.join(\"..\", \"data\", \"extracted_data\", \"submissions_data.ndjson\")\n",
    "\n",
    "assert os.path.isfile(comments_data_path) is True\n",
    "assert os.path.isfile(submissions_data_path) is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9451975d-e75f-404a-a0d4-d9eb9b19e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_db(db_engine, data_file: str, table_name: str, selected_columns: list[str]):\n",
    "    \"\"\"\n",
    "    Upload to database\n",
    "    \"\"\"\n",
    "\n",
    "    assert os.path.isfile(data_file) is True\n",
    "    assert data_file.endswith('.ndjson') is True\n",
    "\n",
    "    with open(data_file, 'r') as f:\n",
    "        done = False\n",
    "        it = 1\n",
    "        while not done:\n",
    "            jsons = []\n",
    "            # 1000 lines at a time\n",
    "            for i in range(1000):\n",
    "                line = f.readline().strip()\n",
    "\n",
    "                # end of line is reached\n",
    "                if not line:\n",
    "                    done = True\n",
    "                    break\n",
    "\n",
    "                json_line = json.loads(line)\n",
    "                jsons.append(json_line)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            df = pd.DataFrame(jsons)\n",
    "            # only select relevant columns\n",
    "            for col in selected_columns:\n",
    "                # NOTE: some json entries may not contain the selected column,  \n",
    "                # we will that as NA\n",
    "                if col not in df.columns:\n",
    "                    df[col] = pd.NA\n",
    "\n",
    "            df = df[selected_columns]\n",
    "            df.to_sql(table_name, db_engine, if_exists='append', index=False)\n",
    "            print(f'iteration #{it}: data written to {table_name} successfully.')\n",
    "            it += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694f3d48-7ac8-40a5-a6fa-5d51e978fed7",
   "metadata": {},
   "source": [
    "#### Create database engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "618ce8f0-b1da-47b1-8f8c-5e4ccba4e75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_path = '../.env'\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "def get_db_url(db_name):\n",
    "    db_str = 'postgresql+psycopg2://{}:{}@{}:{}/{}'\n",
    "    return db_str.format(\n",
    "        os.getenv('DB_USERNAME'),\n",
    "        os.getenv('DB_PASSWORD'),\n",
    "        os.getenv('DB_HOST'),\n",
    "        os.getenv('DB_PORT'),\n",
    "        db_name\n",
    "    )\n",
    "\n",
    "db_url = get_db_url('reddit')\n",
    "db_engine = create_engine(db_url)\n",
    "\n",
    "# TODO: ensure db_engine is successfully created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b34a83-7e35-49d6-a4fa-1f01a83a159b",
   "metadata": {},
   "source": [
    "#### Upload data to database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b1b68a-1cc7-4082-83ab-da9649056c08",
   "metadata": {},
   "source": [
    "Comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50ed899-1fd1-48a6-9c99-9908e1fdb03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define relevant comment columns\n",
    "# this is the result of the EDA we did on the Reddit dataset\n",
    "relevant_comment_columns = [\n",
    "    \"id\", \"archived\", \"author\", \"author_created_utc\", \n",
    "    \"author_fullname\", \"body\", \"controversiality\", \n",
    "    \"created_utc\", \"downs\", \"locked\", \n",
    "    \"name\", \"num_reports\", \"parent_id\", \"permalink\", \n",
    "    \"retrieved_on\", \"score\", \"subreddit\", \n",
    "    \"subreddit_id\", \"subreddit_name_prefixed\", \n",
    "    \"subreddit_type\", \"total_awards_received\", \n",
    "    \"updated_on\", \"ups\"\n",
    "]\n",
    "\n",
    "upload_to_db(db_engine, comments_data_path, 'comments_test', relevant_comment_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192e872d-d8e3-4174-a9c0-4c66548e7421",
   "metadata": {},
   "source": [
    "Submissions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaab3eb-f490-4c96-a866-ce2ee9ffe4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define relevant submission columns\n",
    "# this is the result of the EDA we did on the Reddit dataset\n",
    "relevant_submission_columns = [\n",
    "    \"id\", \n",
    "    \"archived\", \n",
    "    \"author\", \n",
    "    \"author_created_utc\", \n",
    "    \"author_fullname\", \n",
    "    \"created_utc\", \n",
    "    \"downs\", \n",
    "    \"is_self\", \n",
    "    \"locked\", \n",
    "    \"name\", \n",
    "    \"num_comments\", \n",
    "    \"num_crossposts\", \n",
    "    \"num_reports\", \n",
    "    \"permalink\", \n",
    "    \"score\", \n",
    "    \"selftext\", \n",
    "    \"spoiler\", \n",
    "    \"subreddit\", \n",
    "    \"subreddit_id\", \n",
    "    \"subreddit_name_prefixed\", \n",
    "    \"subreddit_subscribers\", \n",
    "    \"subreddit_type\", \n",
    "    \"title\", \n",
    "    \"total_awards_received\", \n",
    "    \"ups\", \n",
    "    \"upvote_ratio\", \n",
    "    \"url\"\n",
    "]\n",
    "\n",
    "upload_to_db(db_engine, submissions_data_path, 'submissions_test', relevant_submission_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c141d3-a53f-4e74-8315-72b21a69c5c5",
   "metadata": {},
   "source": [
    "### Normalize Reddit dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84042cf-2d70-47f9-806b-a84f5dc03f8f",
   "metadata": {},
   "source": [
    "#### `Subreddit`\n",
    "From inspection of the two data tables `submissions` and `comments` and their attributes, it appears that the dataset is fairly denormalized.\n",
    "For instance, entries in both `submissions` and `comments` have attributes `subreddit`, `subreddit_id`, `subreddit_name_prefixed`, `subreddit_type`. Entries in `submissions` also contain `subreddit_subscribers`, which is the number of subscribers to the subreddit. This might be useful to track the number of subsribers to a subreddit over time. `subreddit_name_prefixed` is the prefixed subreddit name, which can be easily constructed from `subreddit` in this format `r/[subreddit]`, thus not too relevant and can be excluded.\n",
    "\n",
    "\n",
    "From the observations, `subreddit` can be converted to its own entity set which allows retrieve info about subreddits more easily. This makes sense, as in our dataset, there are only posts and comments from 13 different subreddits.\n",
    "\n",
    "In this code below, we will further explore information on subreddits stored in both `submissions` and `comments` and create a seperate table for `subreddit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8584ee8b-24b5-44d3-aa30-0ae3b3909997",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_columns = [\n",
    "    \"subreddit\", \n",
    "    \"subreddit_id\", \n",
    "    \"subreddit_name_prefixed\", \n",
    "    \"subreddit_subscribers\", \n",
    "    \"subreddit_type\" \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9119c0c8-23ec-49d2-b19e-f51ff3f00ffc",
   "metadata": {},
   "source": [
    "#### Connect to database using `psycopg2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75003735-a5e6-4f56-9cbd-3b661dd5c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    dbname='reddit',\n",
    "    user=os.getenv('DB_USERNAME'),\n",
    "    password=os.getenv('DB_PASSWORD'),\n",
    "    host=os.getenv('DB_HOST'),\n",
    "    port=os.getenv('DB_PORT')\n",
    ")\n",
    "\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec16632-9523-42cd-b969-724f8b1b0286",
   "metadata": {},
   "source": [
    "Query subreddits from `submissions` and `comments`, union them to find all subreddits and store it in new `subreddit` tables.\n",
    "The attributes of `subreddit` includues `subreddit_name`, `subreddit_id`, `subreddit_name_prefixed` and `subreddit_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ad5e9f-6827-4666-8a5d-56517d24cec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_cmd = '''\n",
    "\n",
    "SELECT \n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c15884-de51-4ab4-a78b-b0a6c369e3f9",
   "metadata": {},
   "source": [
    "#### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c86c6ec-13e2-4d7c-ac43-d0c552348905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_101_venv",
   "language": "python",
   "name": "venv_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

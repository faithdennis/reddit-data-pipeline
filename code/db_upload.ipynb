{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837256f8-8efb-468b-bc44-68e46b85612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd9c9ee8-8844-45a5-84fa-c4f20877d68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026f80d3-d54b-4a1f-8b69-c3530cf76b31",
   "metadata": {},
   "source": [
    "#### Check if data files have been extracted\n",
    "\n",
    "In theory, this notebook should be run after `EDA.ipynb` where we perform our intial data exploratory.\n",
    "In that notebook, we unzip the compressed data file into two `.ndjson` for submission and comment data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91b5f3d7-a6da-437a-ab5d-44ebea19195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_data_path = os.path.join(\"..\", \"data\", \"extracted_data\", \"comments_data.ndjson\")\n",
    "submissions_data_path = os.path.join(\"..\", \"data\", \"extracted_data\", \"submissions_data.ndjson\")\n",
    "\n",
    "assert os.path.isfile(comments_data_path) is True\n",
    "assert os.path.isfile(submissions_data_path) is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9451975d-e75f-404a-a0d4-d9eb9b19e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_db(db_engine, data_file: str, table_name: str, selected_columns: list[str]):\n",
    "    \"\"\"\n",
    "    Upload \n",
    "    \"\"\"\n",
    "\n",
    "    assert os.path.isfile(data_file) is True\n",
    "    assert data_file.endswith('.ndjson') is True\n",
    "\n",
    "    with open(data_file, 'r') as f:\n",
    "        done = False\n",
    "        it = 1\n",
    "        while not done:\n",
    "            jsons = []\n",
    "            # 1000 lines at a time\n",
    "            for i in range(1000):\n",
    "                line = f.readline().strip()\n",
    "\n",
    "                # end of line is reached\n",
    "                if not line:\n",
    "                    done = True\n",
    "                    break\n",
    "\n",
    "                json_line = json.loads(line)\n",
    "                jsons.append(json_line)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            df = pd.DataFrame(jsons)\n",
    "            # only select relevant columns\n",
    "            for col in selected_columns:\n",
    "                # NOTE: some json entries may not contain the selected column,  \n",
    "                # we will that as NA\n",
    "                if col not in df.columns:\n",
    "                    df[col] = pd.NA\n",
    "\n",
    "            df = df[selected_columns]\n",
    "            df.to_sql(table_name, db_engine, if_exists='append', index=False)\n",
    "            print(f'iteration #{it}: data written to {table_name} successfully.')\n",
    "            iter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694f3d48-7ac8-40a5-a6fa-5d51e978fed7",
   "metadata": {},
   "source": [
    "#### Create database engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "618ce8f0-b1da-47b1-8f8c-5e4ccba4e75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_path = '../.env'\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "def get_db_url(db_name):\n",
    "    db_str = 'postgresql+psycopg2://{}:{}@{}:{}/{}'\n",
    "    return db_str.format(\n",
    "        os.getenv('DB_USERNAME'),\n",
    "        os.getenv('DB_PASSWORD'),\n",
    "        os.getenv('DB_HOST'),\n",
    "        os.getenv('DB_PORT'),\n",
    "        db_name\n",
    "    )\n",
    "\n",
    "db_url = get_db_url('reddit')\n",
    "db_engine = create_engine(db_url)\n",
    "\n",
    "# TODO: ensure db_engine is successfully created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b34a83-7e35-49d6-a4fa-1f01a83a159b",
   "metadata": {},
   "source": [
    "#### Upload data to database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b1b68a-1cc7-4082-83ab-da9649056c08",
   "metadata": {},
   "source": [
    "Comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50ed899-1fd1-48a6-9c99-9908e1fdb03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define relevant comment columns\n",
    "# this is the result of the EDA we did on the Reddit dataset\n",
    "relevant_comment_columns = [\n",
    "    'author',\n",
    "    'author_created_utc',\n",
    "    'body',\n",
    "    'created_utc',\n",
    "    'id',\n",
    "    'locked',\n",
    "    'parent_id',\n",
    "    'permalink',\n",
    "    'retrieved_on',\n",
    "    'score',\n",
    "    'subreddit',\n",
    "    'subreddit_id',\n",
    "    'subreddit_name_prefixed',\n",
    "    'subreddit_type',\n",
    "    'archived',\n",
    "    'downs',\n",
    "    'updated_on',\n",
    "    'ups'\n",
    "]\n",
    "\n",
    "upload_to_db(db_engine, comments_data_path, 'comments', relevant_comment_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192e872d-d8e3-4174-a9c0-4c66548e7421",
   "metadata": {},
   "source": [
    "Submissions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaab3eb-f490-4c96-a866-ce2ee9ffe4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define relevant submission columns\n",
    "# this is the result of the EDA we did on the Reddit dataset\n",
    "relevant_submission_columns = [\n",
    "    \"id\", \"downs\", \"ups\", \"archived\", \"author\", \n",
    "    \"author_created_utc\", \"subreddit\", \"subreddit_id\", \n",
    "    \"subreddit_subscribers\", \"subreddit_type\", \"title\", \n",
    "    \"url\", \"num_comments\", \"permalink\", \n",
    "    \"is_self\", \"selftext\", \"created_utc\", \"spoiler\", \"locked\"\n",
    "]\n",
    "\n",
    "upload_to_db(db_engine, submissions_data_path, 'submissions', relevant_submission_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0de187-7bf9-4ec4-9b5a-f31486f0939e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (data101.venv)",
   "language": "python",
   "name": "data101.venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
